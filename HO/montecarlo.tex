As highlighted in the previous section, the initial goal of the simulation is the numerical evaluation
of the integral in equation \ref{eqn:integral}.
The random variables needed for the integration are the Feynman paths\\ $E_{J}\equiv\{x_{0},\dots,x_{N-1}\}_{J}$.

To ensure that each new configuration is extracted following the right probability distribution
$\nicefrac{e^{-S}}{Z}$, we choose to work with an ergodic Markov chain.
Indeed, an ergodic Markov chain with probability transition matrix $P_{JK}$ is guaranteed to have
an asymptotic distribution $\pi_{J}$ whose form does not depend on the starting configuration; thus, we just need to design an ergodic Markov chain such that $\pi_{J}=\nicefrac{e^{-s}}{Z}$.



A sufficient condition for a Markov chain to be ergodic is for it to obey the detailed balance $\pi_{J}P_{JK}=\pi_{K}P_{KJ}$ and a sufficient condition for a Markov chain to satisfy the detailed balance is to be generated by the Metropolis algorithm. Therefore, it is enough for us to implement the Metropolis algorithm to eventually generate suitable configurations -- \textit{i.e.} suitable Feynman paths.

The Metropolis Monte Carlo algorithm is composed of two steps

\begin{enumerate}
  \item \textbf{Proposal:} given an initial state $E_{J}$, a state $E_{K}$ with transition probability $Q_{JK}$ satisfying
        the microreversibility condition\footnote{$Q_{JK}=Q_{KJ}$} is proposed;
  \item \textbf{Accept/Reject:} to generate events with asymptotic probability distribution $\pi_{J} = \nicefrac{R_{J}}{\sum_{J}R_{J}}$\footnote{Note that this has the same form of $\nicefrac{e^{-S}}{Z}$.},
        the new configuration is accepted with probability $1$ if $R_{K}\ge R_{J}$ and with probability
        $\nicefrac{R_K}{R_J}$ otherwise. Thus, we construct a transition probability matrix
      \begin{align}
          P_{JK}=
          \begin{cases}
            Q_{JK} \text{ if } R_{K}\ge R_{J}\\
            Q_{JK}\dfrac{R_{K}}{R_{J}} \text{ if } R_{K}<R_{J}
          \end{cases}.
        \end{align}
\end{enumerate}
If a new configuration is rejected, the algorithm \\restarts from $E_{J}$ and a new proposal is made.

In our implementation the asymptotic distribution is $\nicefrac{e ^{-S}}{Z}$, so a new proposal $E_{K}$ is certainly accepted if the action decreases\footnote{$\Delta S = S[E_{K}]-S[E_{J}] < 0$.}
and accepted with probability $e ^{-\left(S[E_{K}]-S[E_{J}]\right)}$ if the action increases.
Configurations that correspond to larger actions are still allowed, but they are at a disadvantage compared to those that lead to smaller actions.
The algorithm makes a new proposal for each coordinate $x_i$, one at a time, of the starting configuration. That is
\begin{align}
  &E_{K} = \{x_{0}, \dots, x_{i}, \dots, x_{N-1}\} \mapsto \notag \\
  &E_{K+1}=\{x_{0}',\dots,x_{i},\dots x_{N-1}\} \mapsto \notag \\
  &\vdots \notag \\
  &E_{K+N}=\{x_{0}', \dots,x_{i}', \dots, x_{N-1}'\}.
\end{align}
Once every coordinate has undergone the accept/reject phase we
say that a \textit{sweep} has happened and \textit{Markovian time} increases by one unit (figure \ref{fig:sweep}).
\begin{figure}[ht]
  \centering
  \ctikzfig{sweep}
  \caption{\label{fig:sweep}The elementary step of the Markov chain consists of the (potential) update of one coordinate, after the elementary step has happened for every coordinate a sweep is completed. The sweep index
    is called \textit{Markovian time}. After a sufficiently large number of sweeps, the chain
    is said to be thermalized and each new random $x_{i}$ will be extracted following $\nicefrac{e ^{-S}}{Z}$. Physically, a new sweep is a new Feynman path.}
\end{figure}


The proposal for an updated coordinate  $x_{i}' \mapsfrom x_{i}$ is chosen in the closed interval $[x_{i} - \Delta, x_{i} +\Delta]$ ($\Delta$ is
a positive, real algorithm parameter that does not impact the physics)
and it depends on a random number $r_{1}$, generated with uniform distribution
between $0$ and $1$\footnote{As $r_{1}$ is chosen with a flat distribution microreversibility is guaranted -- \textit{i.e.} the transition $x_{i}\mapsto x_{i}' $ is equiprobable to the transition $x_{i}'\mapsto x_{i}$.}
\begin{align}
  \label{eqn:proposal}
  x_{i}' = x_{i}+ 2\Delta \left(r_{1} - \frac{1}{2}\right).
\end{align}
The accept/reject phase of the algorithm is implemented with a second random number $r_{2}$, also generated with uniform distribution
between $0$ and $1$
\begin{align}
  \begin{cases}
    \text{if } e ^{-\Delta S} \ge r_{2} \text{ accept } x_{i}'  &\implies x_{i} \mapsto x_{i}' \neq x_{i} \\
    \text{if }e ^{-\Delta S} < r_{2} \text{ reject } x_{i}' &\implies x_{i} \mapsto x_{i}' \equiv x_{i}
  \end{cases}.
\end{align}
Since the chain only tries to update one coordinate at a time, if we call the coordinate shift $\delta x_{i}$, the
corresponding variation of the action is
\begin{align}
  \Delta S = \frac{m}{2a}\delta x_{i}\qty[\left(2+a ^2\w ^2\right)\left(2x_{i}+\delta x_{i}\right) - 2(x_{i+1}+x_{{i-1}})].
\end{align}
Now the discussion of the experiment can begin, starting from the thermalization of the chain.
